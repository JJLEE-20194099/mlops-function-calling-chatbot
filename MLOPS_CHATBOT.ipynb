{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "38538308-567a-47e7-8cd9-93e03c2e4a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/tmp/ipykernel_3269333/3108997990.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">5</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: The `airflow.operators.python_operator.PythonOperator` class is deprecated. Please use `</span><span style=\"color: #808000; text-decoration-color: #808000\">'airflow.operators.python.PythonOperator'</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/tmp/ipykernel_3269333/\u001b[0m\u001b[1;33m3108997990.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m5\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: The `airflow.operators.python_operator.PythonOperator` class is deprecated. Please use `\u001b[0m\u001b[33m'airflow.operators.python.PythonOperator'\u001b[0m\u001b[33m`.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "import func_timeout\n",
    "import time\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from consume.utils import Redis\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2cbb639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAiHLi5BQN2Truo7mrSpDRRo6G2TnnUGsA\")\n",
    "\n",
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e51b0482-c574-4a86-9c1a-47937b3bd70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_gemini(input_sentence):\n",
    "    response = model.generate_content(\n",
    "        input_sentence,\n",
    "        safety_settings={\n",
    "            'HARM_CATEGORY_SEXUALLY_EXPLICIT':'block_none',\n",
    "            'HARM_CATEGORY_HATE_SPEECH':'block_none',\n",
    "            'HARM_CATEGORY_HARASSMENT':'block_none',\n",
    "            'HARM_CATEGORY_DANGEROUS_CONTENT':'block_none'\n",
    "        }\n",
    "    )\n",
    "    try:\n",
    "    # print(response.text)\n",
    "        return response.text\n",
    "    except:\n",
    "        print(response.prompt_feedback)\n",
    "        # return None\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "99bdabc8-f309-42af-a495-dd436d3930bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_content_gemini(\"Crawl data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1b751c7-9fb9-4c4e-8b10-1d4a5fa3ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_insights = \"\"\"\n",
    "\n",
    "\n",
    "Q: Who are you?\n",
    "\n",
    "A: I am a chatbot that helps you better understand the MLOPs workflow in the real estate problem of the BKPrice system - A system that solves the existing problems of different systems in terms of expected price results and automation in the real estate problem. Deploying artificial intelligence is a difficult problem, especially the automatic security and high reliability of AI services is one of the major problems today. Traditional design thinking and approach to artificial intelligence problems become less knowledgeable when the specific price prediction problem needs to be updated with data and models over time. Therefore, it raises the issue that there needs to be an automatic and reliable solution in the real estate price prediction problem to minimize risks and costs. There have been many solutions to the problem in terms of algorithms and approaches, including the solution from Biggee. This is an effective solution, but the solution requires many specific information systems to value real estate such as plots. Besides this solution, OneHousing provides a real estate valuation solution. However, the valuation in this solution is not reliable enough because the solution only values ​​based on location and is manual by third-party authentication. Therefore, the study came to a breakthrough decision to solve these shortcomings with a system called BKPrice. The idea of ​​the system is to build a real estate price prediction process that is reliable enough in terms of model output, model evaluation and model deployment automatically. The system provides a service to predict the price of any product and an automatic MLOps stream. To achieve automation and reliability, the BKPrice system performs the following two main tasks: (i) Extracting multiple features, building data and training the trainer with automatic valuation algorithms, (ii) Evaluating the model and deploying the model automatically. In this study, the BKPrice system has thoroughly solved the above two tasks:\n",
    "\n",
    "+ The BKPrice system has a data collection stream, automatically cleaning the data. From those data, the system extracts the specification set and builds a training dataset for artificial intelligence models. To ensure the reliability of the expected results, the system has merged the models and post-processed the results. The processing steps are always optimized to ensure the system works better, has the ability to deploy and expand later.\n",
    "\n",
    "+ The BKPrice system has a mechanism to evaluate models and deploy models automatically. The system has monitored the training model based on the measurements from which it receives the training model, where it is good, where it is bad, and adjusts it appropriately\n",
    "\n",
    "In conclusion, the BKPrice system has met the factors The factors mentioned in the study throughout: (i) Novelty, (ii) Automaticity, (iii) Reliability, (iv) Deployability.\n",
    "\n",
    "Through the problems and solutions mentioned in general, the BKPrice system in particular, the study has the following outstanding suggestions:\n",
    "\n",
    "+ Inheriting the strengths and solving the shortcomings of existing solutions.\n",
    "+ Proposing a reliable real estate price prediction algorithm based on multi-level information\n",
    "+ Building an automatic MLOps flow for the real estate problem and easily modifying it to be available for other artificial intelligence services.+ Making a good stepping stone for different systems in the future\n",
    "\n",
    "------------------------\n",
    "\n",
    "Q: What can I do with you?\n",
    "A: I am a chatbot programmed by Mr. Le Thanh Long during his thesis at Hanoi University of Science and Technology.\n",
    "\n",
    "--------------------\n",
    "Q: Which realestate data source you supported to crawl?\n",
    "A: In demo version, you can crawl data from meeyland source\n",
    "\n",
    "---------------------\n",
    "\n",
    "\n",
    "Q: How to build MLOPs for predict realestate price in production?\n",
    "A: First. You have to crawl data. You extract, transform and insert to database. Moreover, you have to build training dataset to build AI model. To more efficiently, you can ensemble model to make predict result more stable\"\n",
    "-----------\n",
    "\n",
    "Q: What should I do after collecting data?\n",
    "A: Since the collected data has a lot of noise, the collected data needs to be cleaned first and put into a certain format. After the data cleaning step, the cleaned data can be stored in the database and used in the next stages.\n",
    "\n",
    "-----------\n",
    "Q: With the data collected and newly updated into the database, it is possible to build a training set to train the model and continue to update the knowledge for the correct AI service?\n",
    "A: Of course. You can do anything on this clean data file, including training AI model. The process of processing data and building datasets for AI services, people go there is the process of building offline batch data: engineer feature / extract feature, transform feature, ...\n",
    "-----------\n",
    "\n",
    "Q: What kind of training models do you support?\n",
    "A: There are many types of AI models available for training such as:\n",
    "    + Single model:\n",
    "        - cat: CatBoostRegressor\n",
    "        - lgbm: LGBMRegressor\n",
    "        - xgb: XGBRegressor\n",
    "        - abr: AdaBoostRegressor\n",
    "        - gbr: GradientBoostingRegressor\n",
    "        - knr: KNeighborsRegressor\n",
    "        - la: Lasso\n",
    "        - linear: LinearRegression\n",
    "        - mlp: MLPRegressor\n",
    "        - rf: RandomForestRegressor\n",
    "        - ridge: Ridge\n",
    "    + Ensemble model\n",
    "\n",
    "    Moreover, we support 6 versions (version 0-5) of the feature set when training the AI ​​model. Each version includes real estate features, integral utility information, distance features, neighboring real estate features, and features based on Gaussian Mixture Components and Principal component analysis techniques.\n",
    "\n",
    "With 2 cities Ho Chi Minh and Hanoi, you can choose one of the 2 data sets to train the AI ​​model\n",
    "\n",
    "-------------\n",
    "\n",
    "Q: What steps can you help me with in MLOPs?\n",
    "A: I can help you crawl data, clean data và insert data to database. Moreover I can support you many feature set versions and build batch offline data for training model phrase. I also provide you many AI model and monitoring trained model automatically.\n",
    "\n",
    "-------------\n",
    "\n",
    "Q: Where can I monitor the training dataset?\n",
    "A: In the system, I use Feast Framework to monitor the feature set and dataset. You can see at the following link:\n",
    "+ http://localhost:8889/p/datnfeast/data-set\n",
    "+ http://localhost:8890/p/datnfeast/data-set\n",
    "\n",
    "\n",
    "-------------\n",
    "\n",
    "Q: Where can I monitor and observe the data collection and cleaning process  from your system?\n",
    "A: The BKPrice system uses Airflow to schedule and monitor the execution status of tasks, including data collection and processing tasks. You can refer to below links:\n",
    "+ Crawling data monitor: http://localhost:8081/dags/get_raw_data/grid\n",
    "+ Cleaning data monitor: http://localhost:8081/dags/clean_raw_data/grid\n",
    "\n",
    "-------------\n",
    "\n",
    "\n",
    "Q: Where can I see the information of AI model training sessions?\n",
    "A: We are using mlflow framework to manage model training runs. This gives us better control over model training schedule and training time. You can refer to below link: http://localhost:5001/#/experiments/1\n",
    "\n",
    "-------------\n",
    "\n",
    "Q: How to check the results of AI model training?\n",
    "A: After training the AI ​​model, we stored the results to mlflow. You can then monitor the model results and compare them with each other more easily.You can refer to below link: http://localhost:5001/#/experiments/62/runs/8a751b0eaf4d4b06ac74f7ad782b21f1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "87ab61d6-5b21-41d3-bc73-db52c0146856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crawl_data(source = 'meeyland'):\n",
    "    return f\"Start to crawl data from {source}\"\n",
    "\n",
    "def _clean_data(source = 'meeyland'):\n",
    "    return f\"Start to clean data from {source}\"\n",
    "\n",
    "def _insert_data(source = 'meeyland'):\n",
    "    return f\"Start to insert clean data to database\"\n",
    "\n",
    "def _build_offline_batch_data():\n",
    "    return f\"Build Offline batch data to train model\"\n",
    "\n",
    "def _train_price_prediction_model(model_name):\n",
    "    return f\"Start to train {model_name}\"\n",
    "\n",
    "def _get_information_about_train_experiment(experiment_id):\n",
    "    return f\"Get all metrics from {experiment_id}\"\n",
    "\n",
    "def _train_ensemble_model():\n",
    "    return f\"Start to train ensemble model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9afa38c0-8f93-4de1-aa5c-748bed8d0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_description = \"\"\"\n",
    "Function: _crawl_data\n",
    "    Description:\n",
    "        Crawl realestate data from source\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['meeyland', 'muaban']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "\n",
    "Function: _clean_data\n",
    "    Description:\n",
    "        - Clean raw realestate data\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['meeyland', 'muaban']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _insert_data\n",
    "    Description:\n",
    "        - Insert clean data to database\n",
    "    Params:\n",
    "        source\n",
    "        - Enum: ['meeyland', 'muaban']\n",
    "        - Default: 'meeyland'\n",
    "        - Sample: 'meeyland'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _build_offline_batch_data\n",
    "    Decription:\n",
    "        - Build batch data for training AI model: extract feature, transform feature for training AI model phrase\n",
    "    Params:\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _train_price_prediction_model\n",
    "    Description:\n",
    "        - Training Price Prediction Model. Support models: lightgbm, catboost, xgboost\n",
    "    Params:\n",
    "        modelname\n",
    "        - Description: Machine Learning Model. Here is model symbol:\n",
    "            - cat: CatBoostRegressor\n",
    "            - lgbm: LGBMRegressor\n",
    "            - xgb: XGBRegressor\n",
    "            - abr: AdaBoostRegressor\n",
    "            - gbr: GradientBoostingRegressor\n",
    "            - knr: KNeighborsRegressor\n",
    "            - la: Lasso\n",
    "            - linear: LinearRegression\n",
    "            - mlp: MLPRegressor\n",
    "            - rf: RandomForestRegressor\n",
    "            - ridge: Ridge\n",
    "        - Enum: ['cat', 'lgbm', 'xgb', 'abr', 'etr', 'gbr', 'knr', 'la', 'linear', 'mlp', 'rf', 'ridge'],\n",
    "        - Default: 'cat'\n",
    "        - Sample: 'cat'\n",
    "        feature_set_version\n",
    "        - Description: Feature Set of training dataset\n",
    "        - Enum: [0, 1, 2, 3, 4, 5]\n",
    "        - Default: 0\n",
    "        - Sample: 0\n",
    "        city\n",
    "        -Descrition: There are two datasets: Ho Chi Minh Dataset and Ha Noi Dataset. Here is city symbol:\n",
    "            - hn: Ha Noi\n",
    "            - hcm: Ho Chi Minh\n",
    "        - Enum: ['hn', 'hcm']\n",
    "        - Default: 'hn'\n",
    "        - Sample: 'hn'\n",
    "    Output:\n",
    "        - None\n",
    "\n",
    "Function: _get_information_about_train_experiment\n",
    "    Description:\n",
    "        Get machine learning metrics about train experiment:\n",
    "            - explained_variance\n",
    "            - neg_mean_absolute_percentage_error\n",
    "            - neg_root_mean_squared_error\n",
    "            - max_error\n",
    "    Params:\n",
    "        experiment_id\n",
    "        - string\n",
    "        - Default: \"hcm_knr_realestate_DATN_V4\"\n",
    "        - Sample: \"hcm_knr_realestate_DATN_V4\"\n",
    "    Output:\n",
    "        - Information about each training metrics\n",
    "\n",
    "Function: _train_ensemble_model\n",
    "    Description:\n",
    "        - Train ensemble model from single pretrained models: lgbm, xgb, ...\n",
    "    Params:\n",
    "    Output:\n",
    "        - None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f78f2245-7116-4ec8-8453-a8ae9cb216ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROLLER_PROMPT_TEMPLATE = \"\"\"You are a controller, you receive below query from user, utilize the insights and choose what is the best one main action from given functions\n",
    "\n",
    "Query: $$QUERY$$\n",
    "\n",
    "Insights: $$INSIGHTS$$\n",
    "\n",
    "List function:\n",
    "$$FUNCTIONS_DECRIPTION$$\n",
    "\n",
    "The response should be exactly like format and don't say anything else:\n",
    "```json\n",
    "{\n",
    "    \"observation\": <what is the current situation, what should follow>,\n",
    "    \"guidelines\": <what is the most suitable action in this situation and why>,\n",
    "    \"action\": {\n",
    "        \"fn\": <function name 1>,\n",
    "        \"params\": <function param 1>\n",
    "    }\n",
    "}\n",
    "```\n",
    "RESPONSE:\n",
    "```json\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5ce8eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_PROMPT_TEMPLATE =\"\"\"\n",
    "You are a classifier, you receive the following query from the user,utilize the insights  and select which of the following type of query the user request falls into is given in json format with the following {key:value} format: (key is the action type, value is the meaning of the action):\n",
    "{\n",
    "\"MLOPS\": Command queries execute system functions such as: data collection, data cleaning, data insertion, data set construction, AI model training, and AI model monitoring. User query does not include question words, Not a question in query. Must be imperative sentences including request tasks related to data processing, data cleaning, storage, data building to perform AI model training related to real estate.\n",
    "\"OTHERS\": Other types of questions including general questions related to MLOPS pipeline, what can you do,etc. Questions about what your system offers, what it can help me with and how it works,\n",
    "}\n",
    "\n",
    "\"Note\": If user only mention the above issues and ask questions about MLOPs, the question type is still OTHERS\n",
    "\n",
    "Query: $$QUERY$$\n",
    "\n",
    "Insights: $$INSIGHTS$$\n",
    "\n",
    "Please return a single string of the type of the query. Do not return anything else.\n",
    "\n",
    "RESPONSE: query_type\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5993ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAL_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a chatbot were built by Mr. Le Thanh Long for research purposes during his thesis at Hanoi University of Science and Technology. You can use the following insights to answer questions from users.\n",
    "If there is no information in the insight, please answer according to your knowledge. And remember that you answer questions about Machine Learning Operations and AI algorithms in the real estate field.\n",
    "\n",
    "\n",
    "Query: $$QUERY$$\n",
    "\n",
    "Insights: $$INSIGHTS$$\n",
    "\n",
    "RESPONSE:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ee27a9c8-cdce-42d2-a573-a91ec2b9aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_insights = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3f6a78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "984da219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_candidate(obj):\n",
    "    action = obj['action']\n",
    "    try:\n",
    "        if len(action):\n",
    "            return action[0]\n",
    "    except:\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca36ebb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dca83c62-a88c-4476-81bc-3b4932b64aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLOPS'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Ok Insert clean data to database.\"\n",
    "test_inputs = CLASSIFIER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "# eval(generate_content_gemini(test_inputs))\n",
    "response = generate_content_gemini(test_inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "803e957a-cc49-43d4-b384-f5b2bd77b94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We support a wide variety of AI models for real estate price prediction, including:\n",
      "\n",
      "* **Single models:**\n",
      "    * CatBoostRegressor\n",
      "    * LGBMRegressor\n",
      "    * XGBRegressor\n",
      "    * AdaBoostRegressor\n",
      "    * GradientBoostingRegressor\n",
      "    * KNeighborsRegressor\n",
      "    * Lasso\n",
      "    * LinearRegression\n",
      "    * MLPRegressor\n",
      "    * RandomForestRegressor\n",
      "    * Ridge\n",
      "* **Ensemble models:**\n",
      "    * VotingRegressor\n",
      "    * BaggingRegressor\n",
      "    * RandomForestRegressor\n",
      "    * AdaBoostRegressor\n",
      "    * GradientBoostingRegressor\n",
      "\n",
      "We also provide a range of pre-built models that have been trained on large datasets of real estate data. These models can be used to quickly and easily make predictions on new data.\n",
      "\n",
      "In addition to the above, we are constantly adding new models to our library. This ensures that you always have access to the latest and most effective AI models for real estate price prediction.\n"
     ]
    }
   ],
   "source": [
    "query = \"What kind of AI Models you support?\"\n",
    "test_inputs = FORMAL_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights)\n",
    "result = generate_content_gemini(test_inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "473409ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OTHERS'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Ok. I have built train datasets. What kinds of model you support to train price prediction model?\"\n",
    "test_inputs = CLASSIFIER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "# eval(generate_content_gemini(test_inputs))\n",
    "response = generate_content_gemini(test_inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c8646092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_func_obj_by_response(response):\n",
    "    result = json.loads(response.replace(\"`\", \"\").replace(\"\\n\", \"\"))\n",
    "    func_obj = get_best_candidate(result)\n",
    "    return func_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3da2cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fn': '_train_price_prediction_model', 'params': {'modelname': 'cat', 'feature_set_version': '0', 'city': 'hcm'}}\n"
     ]
    }
   ],
   "source": [
    "# query = \"I have build offline batch data. I want to train xgb model with feature set version 5 and Ho Chi Minh dataset\"\n",
    "query = \"I have built dataset. Next step i want to train AI model to predict realestate price. What kinds of model your system support?\"\n",
    "test_inputs = CONTROLLER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "result = generate_content_gemini(test_inputs)\n",
    "func_obj = get_func_obj_by_response(result)\n",
    "print(func_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "29cd0966-bb80-40a4-82a4-4cf8bcebf62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-06-27T20:18:46.037+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1026} INFO\u001b[0m - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "Running on local URL:  http://127.0.0.1:7868\n",
      "[\u001b[34m2024-06-27T20:18:46.634+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1026} INFO\u001b[0m - HTTP Request: GET http://127.0.0.1:7868/startup-events \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "[\u001b[34m2024-06-27T20:18:48.711+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1026} INFO\u001b[0m - HTTP Request: HEAD http://127.0.0.1:7868/ \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "[\u001b[34m2024-06-27T20:18:49.462+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1026} INFO\u001b[0m - HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "Running on public URL: https://f2f979263c941f045e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "[\u001b[34m2024-06-27T20:18:51.776+0000\u001b[0m] {\u001b[34m_client.py:\u001b[0m1026} INFO\u001b[0m - HTTP Request: HEAD https://f2f979263c941f045e.gradio.live \"HTTP/1.1 200 OK\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f2f979263c941f045e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hơ to monitor clean process OTHERS\n",
      "How to monitor training model sessions {\"MLOPS\": null,\"OTHERS\": \"OTHERS\"}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "MAX_THREAD = 10\n",
    "\n",
    "def slow_echo(message, history):\n",
    "    query = message\n",
    "\n",
    "    classifier = CLASSIFIER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights)\n",
    "    response = generate_content_gemini(classifier)\n",
    "\n",
    "    response = response.replace(\"`\", \"\").replace(\"\\n\", \"\")\n",
    "    action_type = response\n",
    "    if action_type == 'MLOPS':\n",
    "\n",
    "        promp_with_input = CONTROLLER_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights).replace(\"$$FUNCTIONS_DECRIPTION$$\", functions_description)\n",
    "        response = generate_content_gemini(promp_with_input)\n",
    "        try:\n",
    "            func_obj = get_func_obj_by_response(response)\n",
    "        except:\n",
    "            for retry in range(3):\n",
    "                func_obj = get_func_obj_by_response(response)\n",
    "                break\n",
    "\n",
    "\n",
    "        if func_obj['fn'] == '_crawl_data':\n",
    "\n",
    "            os.system(\"tmux new-session -d -s crawl 'python chat_get_data.py'\")\n",
    "            yield \"Crawl Job Starting...\"\n",
    "\n",
    "        elif func_obj['fn'] == \"_clean_data\":\n",
    "            os.system(\"tmux new-session -d -s clean 'python chat_clean_data.py'\")\n",
    "            yield \"Clean Job Starting...\"\n",
    "        elif func_obj['fn'] == \"_insert_data\":\n",
    "            os.system(\"tmux new-session -d -s insert 'python chat_insert_data.py'\")\n",
    "            yield \"Insert to Database Job Starting...\"\n",
    "\n",
    "        elif func_obj[\"fn\"] == \"_build_offline_batch_data\":\n",
    "            yield \"Extract Feature Job Starting...\"\n",
    "\n",
    "            bkprice_server = os.getenv(\"BKPRICE_SERVER\")\n",
    "            url = f\"{bkprice_server}/build-offline-batch-data\"\n",
    "\n",
    "\n",
    "            payload = {}\n",
    "            headers = {}\n",
    "\n",
    "            response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "            response = response.json()\n",
    "            example = response['sample_data']\n",
    "\n",
    "            yield f\"Here is an example: {example}\"\n",
    "\n",
    "        elif func_obj[\"fn\"] == \"_train_price_prediction_model\":\n",
    "            bkprice_server = os.getenv(\"BKPRICE_SERVER\")\n",
    "            url = f\"{bkprice_server}/train-ai-model\"\n",
    "\n",
    "            payload = json.dumps(func_obj['params'])\n",
    "            headers = {}\n",
    "\n",
    "            response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "            response = response.json()\n",
    "\n",
    "            yield f\"Start to training AI Model: endpoint ({url}) - payload ({func_obj['params']})\"\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        query = message\n",
    "\n",
    "        classifier = FORMAL_PROMPT_TEMPLATE.replace(\"$$QUERY$$\", query).replace(\"$$INSIGHTS$$\", test_insights)\n",
    "        response = generate_content_gemini(classifier)\n",
    "\n",
    "        print(query, action_type)\n",
    "\n",
    "        yield response\n",
    "\n",
    "\n",
    "\n",
    "    # yield str(func_obj)\n",
    "gr.ChatInterface(slow_echo).launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
